// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.30.0
// source: jobs.sql

package repository

import (
	"context"

	"github.com/jackc/pgx/v5/pgtype"
)

const cancelJob = `-- name: CancelJob :exec
UPDATE jobs
SET
    status = 'cancelled',
    processing_completed_at = NOW()
WHERE id = $1
  AND status = 'pending'
`

// Cancel a pending job
func (q *Queries) CancelJob(ctx context.Context, id pgtype.UUID) error {
	_, err := q.db.Exec(ctx, cancelJob, id)
	return err
}

const claimNextJob = `-- name: ClaimNextJob :one
UPDATE jobs
SET
    status = 'processing',
    processing_started_at = NOW(),
    worker_id = $1
WHERE id = (
    SELECT j.id
    FROM jobs j
    WHERE j.status = 'pending'
      AND j.scheduled_at <= NOW()
      AND (j.tenant_id = $2 OR $2 IS NULL)
      AND (j.queue = $3 OR $3 = '')
    ORDER BY j.priority ASC, j.scheduled_at ASC
    FOR UPDATE SKIP LOCKED
    LIMIT 1
)
RETURNING id, tenant_id, job_type, queue, status, payload, priority, max_retries, retry_count, retry_backoff_seconds, scheduled_at, processing_started_at, processing_completed_at, worker_id, error_message, error_details, timeout_seconds, metadata, created_at, updated_at
`

type ClaimNextJobParams struct {
	WorkerID pgtype.Text `json:"worker_id"`
	TenantID pgtype.UUID `json:"tenant_id"`
	Queue    string      `json:"queue"`
}

// Claim the next pending job using SKIP LOCKED for safe concurrent access
// This query finds the highest priority job that's ready to run
func (q *Queries) ClaimNextJob(ctx context.Context, arg ClaimNextJobParams) (Job, error) {
	row := q.db.QueryRow(ctx, claimNextJob, arg.WorkerID, arg.TenantID, arg.Queue)
	var i Job
	err := row.Scan(
		&i.ID,
		&i.TenantID,
		&i.JobType,
		&i.Queue,
		&i.Status,
		&i.Payload,
		&i.Priority,
		&i.MaxRetries,
		&i.RetryCount,
		&i.RetryBackoffSeconds,
		&i.ScheduledAt,
		&i.ProcessingStartedAt,
		&i.ProcessingCompletedAt,
		&i.WorkerID,
		&i.ErrorMessage,
		&i.ErrorDetails,
		&i.TimeoutSeconds,
		&i.Metadata,
		&i.CreatedAt,
		&i.UpdatedAt,
	)
	return i, err
}

const completeJob = `-- name: CompleteJob :exec
UPDATE jobs
SET
    status = 'completed',
    processing_completed_at = NOW()
WHERE id = $1
  AND status = 'processing'
`

// Mark a job as completed
func (q *Queries) CompleteJob(ctx context.Context, id pgtype.UUID) error {
	_, err := q.db.Exec(ctx, completeJob, id)
	return err
}

const countJobsByStatus = `-- name: CountJobsByStatus :one
SELECT COUNT(*)
FROM jobs
WHERE status = $1
  AND (tenant_id = $2 OR $2 IS NULL)
`

type CountJobsByStatusParams struct {
	Status   string      `json:"status"`
	TenantID pgtype.UUID `json:"tenant_id"`
}

// Count jobs by status
func (q *Queries) CountJobsByStatus(ctx context.Context, arg CountJobsByStatusParams) (int64, error) {
	row := q.db.QueryRow(ctx, countJobsByStatus, arg.Status, arg.TenantID)
	var count int64
	err := row.Scan(&count)
	return count, err
}

const deleteOldCompletedJobs = `-- name: DeleteOldCompletedJobs :exec
DELETE FROM jobs
WHERE status IN ('completed', 'failed', 'cancelled')
  AND processing_completed_at < $1
`

// Cleanup old completed jobs (history is preserved in job_history table)
// Delete jobs older than the specified timestamp
func (q *Queries) DeleteOldCompletedJobs(ctx context.Context, processingCompletedAt pgtype.Timestamptz) error {
	_, err := q.db.Exec(ctx, deleteOldCompletedJobs, processingCompletedAt)
	return err
}

const enqueueJob = `-- name: EnqueueJob :one
INSERT INTO jobs (
    tenant_id,
    job_type,
    queue,
    payload,
    priority,
    max_retries,
    scheduled_at,
    timeout_seconds,
    metadata
) VALUES (
    $1, $2, $3, $4, $5, $6, $7, $8, $9
) RETURNING id, tenant_id, job_type, queue, status, payload, priority, max_retries, retry_count, retry_backoff_seconds, scheduled_at, processing_started_at, processing_completed_at, worker_id, error_message, error_details, timeout_seconds, metadata, created_at, updated_at
`

type EnqueueJobParams struct {
	TenantID       pgtype.UUID        `json:"tenant_id"`
	JobType        string             `json:"job_type"`
	Queue          string             `json:"queue"`
	Payload        []byte             `json:"payload"`
	Priority       int32              `json:"priority"`
	MaxRetries     int32              `json:"max_retries"`
	ScheduledAt    pgtype.Timestamptz `json:"scheduled_at"`
	TimeoutSeconds int32              `json:"timeout_seconds"`
	Metadata       []byte             `json:"metadata"`
}

// Insert a new job into the queue
func (q *Queries) EnqueueJob(ctx context.Context, arg EnqueueJobParams) (Job, error) {
	row := q.db.QueryRow(ctx, enqueueJob,
		arg.TenantID,
		arg.JobType,
		arg.Queue,
		arg.Payload,
		arg.Priority,
		arg.MaxRetries,
		arg.ScheduledAt,
		arg.TimeoutSeconds,
		arg.Metadata,
	)
	var i Job
	err := row.Scan(
		&i.ID,
		&i.TenantID,
		&i.JobType,
		&i.Queue,
		&i.Status,
		&i.Payload,
		&i.Priority,
		&i.MaxRetries,
		&i.RetryCount,
		&i.RetryBackoffSeconds,
		&i.ScheduledAt,
		&i.ProcessingStartedAt,
		&i.ProcessingCompletedAt,
		&i.WorkerID,
		&i.ErrorMessage,
		&i.ErrorDetails,
		&i.TimeoutSeconds,
		&i.Metadata,
		&i.CreatedAt,
		&i.UpdatedAt,
	)
	return i, err
}

const failJob = `-- name: FailJob :one
UPDATE jobs
SET
    status = CASE
        WHEN retry_count + 1 < max_retries THEN 'pending'
        ELSE 'failed'
    END,
    retry_count = retry_count + 1,
    scheduled_at = CASE
        WHEN retry_count + 1 < max_retries
        THEN NOW() + (retry_backoff_seconds * POWER(2, retry_count) || ' seconds')::INTERVAL
        ELSE scheduled_at
    END,
    processing_completed_at = CASE
        WHEN retry_count + 1 >= max_retries THEN NOW()
        ELSE NULL
    END,
    worker_id = CASE
        WHEN retry_count + 1 < max_retries THEN NULL
        ELSE worker_id
    END,
    processing_started_at = CASE
        WHEN retry_count + 1 < max_retries THEN NULL
        ELSE processing_started_at
    END,
    error_message = $2,
    error_details = $3
WHERE id = $1
  AND status = 'processing'
RETURNING id, tenant_id, job_type, queue, status, payload, priority, max_retries, retry_count, retry_backoff_seconds, scheduled_at, processing_started_at, processing_completed_at, worker_id, error_message, error_details, timeout_seconds, metadata, created_at, updated_at
`

type FailJobParams struct {
	ID           pgtype.UUID `json:"id"`
	ErrorMessage pgtype.Text `json:"error_message"`
	ErrorDetails []byte      `json:"error_details"`
}

// Mark a job as failed or reschedule it for retry
// If retry_count < max_retries, reschedule; otherwise mark as failed
func (q *Queries) FailJob(ctx context.Context, arg FailJobParams) (Job, error) {
	row := q.db.QueryRow(ctx, failJob, arg.ID, arg.ErrorMessage, arg.ErrorDetails)
	var i Job
	err := row.Scan(
		&i.ID,
		&i.TenantID,
		&i.JobType,
		&i.Queue,
		&i.Status,
		&i.Payload,
		&i.Priority,
		&i.MaxRetries,
		&i.RetryCount,
		&i.RetryBackoffSeconds,
		&i.ScheduledAt,
		&i.ProcessingStartedAt,
		&i.ProcessingCompletedAt,
		&i.WorkerID,
		&i.ErrorMessage,
		&i.ErrorDetails,
		&i.TimeoutSeconds,
		&i.Metadata,
		&i.CreatedAt,
		&i.UpdatedAt,
	)
	return i, err
}

const getJobByID = `-- name: GetJobByID :one
SELECT id, tenant_id, job_type, queue, status, payload, priority, max_retries, retry_count, retry_backoff_seconds, scheduled_at, processing_started_at, processing_completed_at, worker_id, error_message, error_details, timeout_seconds, metadata, created_at, updated_at
FROM jobs
WHERE id = $1
LIMIT 1
`

// Fetch a job by ID
func (q *Queries) GetJobByID(ctx context.Context, id pgtype.UUID) (Job, error) {
	row := q.db.QueryRow(ctx, getJobByID, id)
	var i Job
	err := row.Scan(
		&i.ID,
		&i.TenantID,
		&i.JobType,
		&i.Queue,
		&i.Status,
		&i.Payload,
		&i.Priority,
		&i.MaxRetries,
		&i.RetryCount,
		&i.RetryBackoffSeconds,
		&i.ScheduledAt,
		&i.ProcessingStartedAt,
		&i.ProcessingCompletedAt,
		&i.WorkerID,
		&i.ErrorMessage,
		&i.ErrorDetails,
		&i.TimeoutSeconds,
		&i.Metadata,
		&i.CreatedAt,
		&i.UpdatedAt,
	)
	return i, err
}

const getJobStats = `-- name: GetJobStats :one
SELECT
    COUNT(*) FILTER (WHERE status = 'pending') as pending_count,
    COUNT(*) FILTER (WHERE status = 'processing') as processing_count,
    COUNT(*) FILTER (WHERE status = 'completed') as completed_count,
    COUNT(*) FILTER (WHERE status = 'failed') as failed_count,
    COUNT(*) FILTER (WHERE status = 'cancelled') as cancelled_count
FROM jobs
WHERE tenant_id = $1 OR $1 IS NULL
`

type GetJobStatsRow struct {
	PendingCount    int64 `json:"pending_count"`
	ProcessingCount int64 `json:"processing_count"`
	CompletedCount  int64 `json:"completed_count"`
	FailedCount     int64 `json:"failed_count"`
	CancelledCount  int64 `json:"cancelled_count"`
}

// Get job queue statistics
func (q *Queries) GetJobStats(ctx context.Context, tenantID pgtype.UUID) (GetJobStatsRow, error) {
	row := q.db.QueryRow(ctx, getJobStats, tenantID)
	var i GetJobStatsRow
	err := row.Scan(
		&i.PendingCount,
		&i.ProcessingCount,
		&i.CompletedCount,
		&i.FailedCount,
		&i.CancelledCount,
	)
	return i, err
}

const listJobsByStatus = `-- name: ListJobsByStatus :many
SELECT id, tenant_id, job_type, queue, status, payload, priority, max_retries, retry_count, retry_backoff_seconds, scheduled_at, processing_started_at, processing_completed_at, worker_id, error_message, error_details, timeout_seconds, metadata, created_at, updated_at
FROM jobs
WHERE status = $1
  AND (tenant_id = $2 OR $2 IS NULL)
ORDER BY created_at DESC
LIMIT $3 OFFSET $4
`

type ListJobsByStatusParams struct {
	Status   string      `json:"status"`
	TenantID pgtype.UUID `json:"tenant_id"`
	Limit    int32       `json:"limit"`
	Offset   int32       `json:"offset"`
}

// List jobs by status for monitoring
func (q *Queries) ListJobsByStatus(ctx context.Context, arg ListJobsByStatusParams) ([]Job, error) {
	rows, err := q.db.Query(ctx, listJobsByStatus,
		arg.Status,
		arg.TenantID,
		arg.Limit,
		arg.Offset,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []Job{}
	for rows.Next() {
		var i Job
		if err := rows.Scan(
			&i.ID,
			&i.TenantID,
			&i.JobType,
			&i.Queue,
			&i.Status,
			&i.Payload,
			&i.Priority,
			&i.MaxRetries,
			&i.RetryCount,
			&i.RetryBackoffSeconds,
			&i.ScheduledAt,
			&i.ProcessingStartedAt,
			&i.ProcessingCompletedAt,
			&i.WorkerID,
			&i.ErrorMessage,
			&i.ErrorDetails,
			&i.TimeoutSeconds,
			&i.Metadata,
			&i.CreatedAt,
			&i.UpdatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}
